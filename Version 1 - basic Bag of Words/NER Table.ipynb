{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a207dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray stroke color because /'P0' is an invalid float value\n"
     ]
    }
   ],
   "source": [
    "#TASK: Parse PDFs in a directory, extract text and metadata, and save to CSV\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#Iterate over all PDF files in the directory\n",
    "PDF_DIR = Path(\"countries_edited\")\n",
    "OUTPUT_CSV = \"document.csv\"\n",
    "rows = []\n",
    "for pdf_path in PDF_DIR.glob(\"*.pdf\"):\n",
    "    all_text = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                all_text.append(text)\n",
    "\n",
    "    full_text = \"\\n\".join(all_text)\n",
    "\n",
    "#Extract metadata from filename\n",
    "    stem = pdf_path.stem              \n",
    "    parts = stem.split(\"_\")\n",
    "\n",
    "    country = parts[0] if len(parts) > 0 else None\n",
    "    year = parts[1] if len(parts) > 1 and parts[1].isdigit() else None\n",
    "    strategy_name = \"_\".join(parts[2:]) if len(parts) > 2 else None\n",
    "\n",
    "    rows.append({\n",
    "        \"doc_id\": f\"{country}_{year}\" if year else country,\n",
    "        \"country\": country,\n",
    "        \"year\": year,\n",
    "        \"strategy_name\": strategy_name,\n",
    "        \"file_name\": pdf_path.name,\n",
    "        \"text\": full_text\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Convert year to numeric, setting errors to NaN for non-numeric values\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44706b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK: Perform NER on the text data and append entities to the CSV\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "#Load data\n",
    "df = pd.read_csv(\"document.csv\")\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\n",
    "\n",
    "#Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Run NER\n",
    "docs = list(nlp.pipe(df[\"text\"].tolist(), batch_size=32))\n",
    "\n",
    "#Define NER types to extract\n",
    "NER_TYPES = [\"ORG\", \"PERSON\"]\n",
    "\n",
    "#Initialize columns for each NER type\n",
    "for ner in NER_TYPES:\n",
    "    df[f\"entities_{ner}\"] = [[] for _ in range(len(df))]\n",
    "for i, doc in enumerate(docs):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in NER_TYPES:\n",
    "            df.at[i, f\"entities_{ent.label_}\"].append(ent.text)\n",
    "\n",
    "# Optional: deduplicate entities per cell\n",
    "for ner in NER_TYPES:\n",
    "    df[f\"entities_{ner}\"] = df[f\"entities_{ner}\"].apply(\n",
    "        lambda x: list(dict.fromkeys(x))\n",
    "    )\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"document.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421cf959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40d2b00714f426ebe1496f369be854c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=''), HTML(value=''), Text(value='', description='Correct Name:', style=TextStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# --- SETTINGS ---\n",
    "INPUT_FILE = \"document.csv\"\n",
    "OUTPUT_FILE = \"classified_entities.csv\"\n",
    "NER_TYPES = [\"ORG\", \"GPE\", \"PERSON\", \"NORP\"]\n",
    "\n",
    "# 1. LOAD DATA & RUN NER\n",
    "if not os.path.exists(OUTPUT_FILE):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\n",
    "    docs = list(nlp.pipe(df[\"text\"].tolist(), batch_size=32))\n",
    "    entity_data = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        seen_entities = set()\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in NER_TYPES and ent.text not in seen_entities:\n",
    "                entity_data.append({\n",
    "                    \"original_doc_index\": i,\n",
    "                    \"entity_name\": ent.text,\n",
    "                    \"ner_label\": ent.label_,\n",
    "                    \"quadruple_helix_category\": \"\"\n",
    "                })\n",
    "                seen_entities.add(ent.text)\n",
    "    df_to_label = pd.DataFrame(entity_data)\n",
    "    df_to_label.to_csv(OUTPUT_FILE, index=False)\n",
    "else:\n",
    "    df_to_label = pd.read_csv(OUTPUT_FILE)\n",
    "\n",
    "# 2. UI LOGIC\n",
    "unlabeled = df_to_label[df_to_label[\"quadruple_helix_category\"].isna() | (df_to_label[\"quadruple_helix_category\"] == \"\")]\n",
    "current_index = int(unlabeled.index.min() if not unlabeled.empty else len(df_to_label))\n",
    "\n",
    "# UI Elements\n",
    "progress_label = widgets.Label(value=\"\")\n",
    "# New Edit Field\n",
    "name_input = widgets.Text(description='Correct Name:', style={'description_width': 'initial'})\n",
    "label_text = widgets.HTML()\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_display():\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        if current_index < len(df_to_label):\n",
    "            row = df_to_label.iloc[current_index]\n",
    "            progress_label.value = f\"Progress: {current_index}/{len(df_to_label)}\"\n",
    "            name_input.value = row['entity_name'] # Pre-fill with detected name\n",
    "            label_text.value = f\"\"\"\n",
    "                <div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 8px; background-color: #f9f9f9; margin-bottom: 10px;\">\n",
    "                    <span style=\"color: #666;\">Original NER Label: <b>{row['ner_label']}</b></span>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "        else:\n",
    "            progress_label.value = \"Done!\"\n",
    "            label_text.value = \"<h3>✅ All entities classified!</h3>\"\n",
    "            name_input.layout.display = 'none'\n",
    "\n",
    "def save_and_next(category):\n",
    "    global current_index\n",
    "    if current_index < len(df_to_label):\n",
    "        # Update both columns: Category AND the potentially edited Name\n",
    "        df_to_label.at[current_index, 'entity_name'] = name_input.value\n",
    "        df_to_label.at[current_index, 'quadruple_helix_category'] = category\n",
    "        df_to_label.to_csv(OUTPUT_FILE, index=False)\n",
    "        current_index += 1\n",
    "        update_display()\n",
    "\n",
    "def go_back(b):\n",
    "    global current_index\n",
    "    if current_index > 0:\n",
    "        current_index -= 1\n",
    "        update_display()\n",
    "\n",
    "# Buttons\n",
    "categories = [\"Academia\", \"Industry\", \"Government\", \"Civil Society\", \"Skip\"]\n",
    "btns = [widgets.Button(description=c, button_style='info' if c != \"Skip\" else '') for c in categories]\n",
    "for i, btn in enumerate(btns):\n",
    "    btn.on_click(lambda b, c=categories[i]: save_and_next(c))\n",
    "\n",
    "back_btn = widgets.Button(description=\"⬅ Back\", button_style='')\n",
    "back_btn.on_click(go_back)\n",
    "\n",
    "# Layout\n",
    "display(widgets.VBox([\n",
    "    progress_label,\n",
    "    label_text,\n",
    "    name_input, # Display the editable field\n",
    "    widgets.HBox(btns),\n",
    "    widgets.HTML(\"<br>\"),\n",
    "    back_btn,\n",
    "    output\n",
    "]))\n",
    "\n",
    "update_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

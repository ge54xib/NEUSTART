{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# 1. Load data\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(\"document.csv\")\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\n",
    "\n",
    "# 2. Load spaCy model\n",
    "# ---------------------------------------------------------\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 3. Process Text (Run Pipeline)\n",
    "# ---------------------------------------------------------\n",
    "# We run the pipe once to get both NER and Dependency data\n",
    "docs = list(nlp.pipe(df[\"text\"].tolist(), batch_size=32))\n",
    "\n",
    "# 4. Define Extraction Logic\n",
    "# ---------------------------------------------------------\n",
    "NER_TYPES = [\"ORG\", \"PERSON\"]\n",
    "\n",
    "# Initialize columns\n",
    "for ner in NER_TYPES:\n",
    "    df[f\"entities_{ner}\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "# New column for dependency context\n",
    "df[\"entity_context\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    temp_deps = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in NER_TYPES:\n",
    "            # A. Standard NER Extraction\n",
    "            df.at[i, f\"entities_{ent.label_}\"].append(ent.text)\n",
    "            \n",
    "            # B. Dependency Parsing (Building up on the entity)\n",
    "            # ent.root.dep_  = The grammatical relationship (e.g., nsubj = Subject)\n",
    "            # ent.root.head.text = The word the entity modifies (e.g., the main verb)\n",
    "            context_str = f\"{ent.text} ({ent.label_}) -> is {ent.root.dep_} of -> {ent.root.head.text}\"\n",
    "            temp_deps.append(context_str)\n",
    "    \n",
    "    # Store the dependency context\n",
    "    df.at[i, \"entity_context\"] = temp_deps\n",
    "\n",
    "# 5. Cleanup and Save\n",
    "# ---------------------------------------------------------\n",
    "# Deduplicate the standard NER columns\n",
    "for ner in NER_TYPES:\n",
    "    df[f\"entities_{ner}\"] = df[f\"entities_{ner}\"].apply(\n",
    "        lambda x: list(dict.fromkeys(x))\n",
    "    )\n",
    "\n",
    "# Save\n",
    "df.to_csv(\"document_with_deps.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete. Sample of extracted dependencies:\")\n",
    "print(df[[\"text\", \"entity_context\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4809d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Setup Data and Model (Assuming df is loaded from previous step)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "docs = list(nlp.pipe(df[\"text\"].tolist(), batch_size=32))\n",
    "NER_TYPES = [\"ORG\", \"PERSON\"]\n",
    "\n",
    "# 2. Build the Graph\n",
    "G = nx.DiGraph() # Directed Graph\n",
    "\n",
    "for doc in docs:\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in NER_TYPES:\n",
    "            source = ent.text\n",
    "            target = ent.root.head.text\n",
    "            relationship = ent.root.dep_\n",
    "            \n",
    "            # Add nodes and edge to the graph\n",
    "            # We differentiate entities by color later, so let's track the type\n",
    "            G.add_node(source, type=\"entity\", label=ent.label_)\n",
    "            G.add_node(target, type=\"head_word\") \n",
    "            G.add_edge(source, target, relation=relationship)\n",
    "\n",
    "# 3. Visualization Configuration\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Layout: 'spring_layout' pushes nodes apart so they don't overlap\n",
    "pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "\n",
    "# Separate nodes by type for coloring\n",
    "entity_nodes = [n for n, attr in G.nodes(data=True) if attr.get(\"type\") == \"entity\"]\n",
    "word_nodes = [n for n, attr in G.nodes(data=True) if attr.get(\"type\") == \"head_word\"]\n",
    "\n",
    "# Draw Nodes\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=entity_nodes, node_color='lightblue', node_size=2000, label=\"Entities\")\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=word_nodes, node_color='lightgrey', node_size=1500, label=\"Head Words\")\n",
    "\n",
    "# Draw Labels (Text inside circles)\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_weight=\"bold\")\n",
    "\n",
    "# Draw Edges\n",
    "nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, arrowstyle='->', arrowsize=20)\n",
    "\n",
    "# Draw Edge Labels (The dependency relationship)\n",
    "edge_labels = nx.get_edge_attributes(G, 'relation')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red')\n",
    "\n",
    "# 4. Show Plot\n",
    "plt.title(\"Entity Dependency Network\")\n",
    "plt.axis('off') # Turn off the x/y axis\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

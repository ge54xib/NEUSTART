{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "557b3792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning folder: countries_edited...\n",
      "Processing ID 0: CAN_2022_Canada's National Quantum Strategy.pdf | Country: CAN, Year: 2022\n",
      "Processing ID 1: GER_2023_Quantum Technologies Conceptual Framework Programme.pdf | Country: GER, Year: 2023\n",
      "Processing ID 2: UK_2023_National Quantum Strategy.pdf | Country: UK, Year: 2023\n",
      "Processing ID 3: USA_2018_NATIONAL STRATEGIC  OVERVIEW FOR QUANTUM  INFORMATION SCIENCE.pdf | Country: USA, Year: 2018\n",
      "Extraction complete. All data saved in 'text_countries_edited.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Text Extraction: Final Version with Doc ID\n",
    "\n",
    "import pymupdf\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from multi_column import column_boxes\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Bereinigt Text: Fixiert Silbentrennung, Initialen und Whitespace.\n",
    "    \"\"\"\n",
    "\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Fix Hyphenation (Word-\\npart -> Wordpart)\n",
    "    text = re.sub(r\"(\\w+)-\\s*\\n\\s*(\\w+)\", r\"\\1\\2\", text)\n",
    "\n",
    "    # 2. Fix Drop Caps (A\\ndvances -> Advances)\n",
    "    text = re.sub(r\"^\\s*([A-Z])\\s*\\n\\s*([a-z])\", r\"\\1\\2\", text)\n",
    "\n",
    "    # 3. Collapse whitespace\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def process_folder(folder_path: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    Iterates through all PDFs in folder_path, extracts metadata from filenames,\n",
    "    extracts/cleans text from pages, and writes everything to a single CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    pdf_dir = Path(folder_path)\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not pdf_dir.exists():\n",
    "        print(f\"Directory not found: {folder_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Scanning folder: {folder_path}...\")\n",
    "\n",
    "    # Open CSV file once for writing\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        # Update Header: Added \"Doc_ID\" as the first column\n",
    "        writer.writerow([\"Doc_ID\", \"Country\", \"Year\", \"Document_Name\", \"Page\", \"Block_ID\", \"text\"])\n",
    "\n",
    "        # Iterate over all PDF files in the directory\n",
    "        pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "\n",
    "        if not pdf_files:\n",
    "            print(\"No PDF files found in the directory.\")\n",
    "            return\n",
    "\n",
    "        # Enumerate gives us a counter (doc_id) starting at 0\n",
    "        for doc_id, pdf_path in enumerate(pdf_files, start=0):\n",
    "\n",
    "            # --- Metadata Extraction ---\n",
    "            parts = pdf_path.stem.split(\"_\")\n",
    "            country = parts[0]\n",
    "\n",
    "            # Check if second part is a year (digits)\n",
    "            year = parts[1] if len(parts) > 1 and parts[1].isdigit() else \"\"\n",
    "\n",
    "            # Join the rest as the document name\n",
    "            doc_name = \"_\".join(parts[2:]) if len(parts) > 2 else \"\"\n",
    "\n",
    "            print(f\"Processing ID {doc_id}: {pdf_path.name} | Country: {country}, Year: {year}\")\n",
    "\n",
    "            try:\n",
    "\n",
    "                # --- PDF Text Extraction ---\n",
    "                doc = pymupdf.open(pdf_path)\n",
    "\n",
    "                for page_num, page in enumerate(doc, start=1):\n",
    "\n",
    "                    # Column detection (Bounding Boxes)\n",
    "                    bboxes = column_boxes(page, footer_margin=50, no_image_text=True)\n",
    "\n",
    "                    for block_id, rect in enumerate(bboxes, start=1):\n",
    "\n",
    "                        # Extract text from the specific box\n",
    "                        raw_text = page.get_text(clip=rect, sort=True)\n",
    "\n",
    "                        # Clean text\n",
    "                        final_text = clean_text(raw_text)\n",
    "\n",
    "                        # Write to CSV if text exists\n",
    "                        if final_text:\n",
    "                            # Added doc_id to the row data\n",
    "                            writer.writerow([doc_id, country, year, doc_name, page_num, block_id, final_text])\n",
    "\n",
    "                doc.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {pdf_path.name}: {e}\")\n",
    "\n",
    "\n",
    "    print(f\"Extraction complete. All data saved in '{output_csv}'.\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define your folder and output filename here\n",
    "    input_folder = \"countries_edited\"\n",
    "    output_filename = \"text_countries_edited.csv\"\n",
    "\n",
    "    process_folder(input_folder, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0bea27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Doc_ID Country  Year                       Document_Name  Page  Block_ID  \\\n",
      "0       0     CAN  2022  Canada's National Quantum Strategy     2         1   \n",
      "1       0     CAN  2022  Canada's National Quantum Strategy     3         1   \n",
      "2       0     CAN  2022  Canada's National Quantum Strategy     3         2   \n",
      "3       0     CAN  2022  Canada's National Quantum Strategy     4         1   \n",
      "4       0     CAN  2022  Canada's National Quantum Strategy     4         2   \n",
      "\n",
      "                                                text  \n",
      "0  Executive summary dvances in quantum science h...  \n",
      "1  Three key missions The National Quantum Strate...  \n",
      "2  Next steps To strengthen Canada‚Äôs quantum ecos...  \n",
      "3                          Canada: A quantum pioneer  \n",
      "4  ince the birth of quantum science more than 10...  \n"
     ]
    }
   ],
   "source": [
    "# Load csv to df\n",
    "import pandas as pd\n",
    "output_filename = \"text_countries_edited.csv\"\n",
    "df = pd.read_csv(output_filename)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced14567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-09 14:57:46,112 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [03:22<00:00, 22.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 739 entities.\n",
      "   Doc_ID  Entity_ID Country  Year                       Document_Name  Page  \\\n",
      "0       0          0     CAN  2022  Canada's National Quantum Strategy     2   \n",
      "1       0          1     CAN  2022  Canada's National Quantum Strategy     3   \n",
      "2       0          2     CAN  2022  Canada's National Quantum Strategy     3   \n",
      "3       0          3     CAN  2022  Canada's National Quantum Strategy     3   \n",
      "4       0          4     CAN  2022  Canada's National Quantum Strategy     4   \n",
      "\n",
      "   Block_ID                          entity_name ner_label qh_category  \\\n",
      "0         1                             Acountry       ORG               \n",
      "1         1        The National Quantum Strategy       ORG               \n",
      "2         1                                  NQS       ORG               \n",
      "3         1                 Government of Canada       ORG               \n",
      "4         3  National Research Council of Canada       ORG               \n",
      "\n",
      "  qh_sub_category qh_exact_category modified_entity_name finalized_entity_name  \n",
      "0                                                                               \n",
      "1                                                                               \n",
      "2                                                                               \n",
      "3                                                                               \n",
      "4                                                                               \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "# 1. LOAD DATA\n",
    "# Load the file and force columns to be strings to avoid the \"bool\" error\n",
    "df = pd.read_csv(\"entities_to_edit.csv\", dtype=str).fillna(\"\")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# We use Block_ID to ensure they appear in the exact same paragraph (Contextual Co-occurrence)\n",
    "scope = ['Doc_ID', 'Block_ID'] \n",
    "# ---------------------\n",
    "\n",
    "print(\"--- Step 1: Pre-processing & Cleaning ---\")\n",
    "\n",
    "# A. CLEANING FUNCTION\n",
    "def clean_name(name):\n",
    "    name = str(name).strip()\n",
    "    # filtering out empty strings or accidental booleans\n",
    "    if name.lower() in [\"\", \"true\", \"false\", \"nan\"]:\n",
    "        return None\n",
    "    return name\n",
    "\n",
    "# Apply cleaning to the FINALIZED column\n",
    "df['clean_name'] = df['finalized_entity_name'].apply(clean_name)\n",
    "\n",
    "# Remove rows where we don't have a valid name\n",
    "df_clean = df.dropna(subset=['clean_name'])\n",
    "\n",
    "print(f\"Original rows: {len(df)} -> Cleaned rows: {len(df_clean)}\")\n",
    "\n",
    "# =========================================================\n",
    "# LOGIC 1: DETECTING RELATIONSHIPS (Building the Graph)\n",
    "# =========================================================\n",
    "print(\"\\n--- Step 2: Building the Network Graph ---\")\n",
    "\n",
    "# Group by Document + Block (Paragraph)\n",
    "grouped = df_clean.groupby(scope)['clean_name'].unique()\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Build a lookup dictionary for Categories (Name -> QH Category)\n",
    "# We take the first non-empty category found for each actor\n",
    "actor_cats = df_clean.groupby('clean_name')['qh_category'].first()\n",
    "nx.set_node_attributes(G, actor_cats.to_dict(), \"category\")\n",
    "\n",
    "# Iterate through groups to find links\n",
    "for actors in grouped:\n",
    "    if len(actors) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Create links between every pair in this block\n",
    "    for u, v in combinations(sorted(actors), 2):\n",
    "        if G.has_edge(u, v):\n",
    "            G[u][v]['weight'] += 1\n",
    "        else:\n",
    "            G.add_edge(u, v, weight=1)\n",
    "\n",
    "print(f\"Graph Created: {G.number_of_nodes()} Actors, {G.number_of_edges()} Links.\")\n",
    "\n",
    "# =========================================================\n",
    "# LOGIC 2: CENTRALITY (Who are the Hubs?)\n",
    "# =========================================================\n",
    "print(\"\\n--- Step 3: Calculating Centrality (Hubs) ---\")\n",
    "\n",
    "if len(G.nodes) > 0:\n",
    "    # Degree Centrality: Number of unique connections\n",
    "    degree_dict = nx.degree_centrality(G)\n",
    "\n",
    "    node_data = []\n",
    "    for node in G.nodes():\n",
    "        node_data.append({\n",
    "            \"Actor_Name\": node,\n",
    "            \"QH_Category\": G.nodes[node].get(\"category\", \"Unknown\"),\n",
    "            \"Connections_Count\": G.degree(node),  # Raw count of partners\n",
    "            \"Centrality_Score\": degree_dict[node] # Normalized score (0-1)\n",
    "        })\n",
    "\n",
    "    nodes_df = pd.DataFrame(node_data).sort_values(\"Connections_Count\", ascending=False)\n",
    "    nodes_df.to_csv(\"network_nodes_centrality.csv\", index=False)\n",
    "    print(\"Saved Hub Analysis to 'network_nodes_centrality.csv'\")\n",
    "    print(nodes_df.head(5))\n",
    "else:\n",
    "    print(\"No connections found. Check if 'finalized_entity_name' is populated.\")\n",
    "\n",
    "# =========================================================\n",
    "# LOGIC 3: TOPIC MAPPING (Sector vs Sector)\n",
    "# =========================================================\n",
    "print(\"\\n--- Step 4: Topic Mapping (Category Matrix) ---\")\n",
    "\n",
    "if len(G.edges) > 0:\n",
    "    cat_interaction_counts = {}\n",
    "\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        cat_u = G.nodes[u].get(\"category\", \"Unknown\")\n",
    "        cat_v = G.nodes[v].get(\"category\", \"Unknown\")\n",
    "        weight = data['weight']\n",
    "        \n",
    "        # Sort so (Gov, Industry) is same as (Industry, Gov)\n",
    "        cats = tuple(sorted([str(cat_u), str(cat_v)]))\n",
    "        \n",
    "        if cats in cat_interaction_counts:\n",
    "            cat_interaction_counts[cats] += weight\n",
    "        else:\n",
    "            cat_interaction_counts[cats] = weight\n",
    "\n",
    "    # Convert to Matrix\n",
    "    matrix_data = [{\"Category_1\": k[0], \"Category_2\": k[1], \"Weight\": v} for k, v in cat_interaction_counts.items()]\n",
    "    matrix_df = pd.DataFrame(matrix_data)\n",
    "\n",
    "    # Mirror for full square matrix\n",
    "    matrix_mirrored = matrix_df.rename(columns={\"Category_1\": \"Category_2\", \"Category_2\": \"Category_1\"})\n",
    "    full_matrix = pd.concat([matrix_df, matrix_mirrored]).drop_duplicates()\n",
    "    \n",
    "    # Pivot\n",
    "    final_matrix = full_matrix.pivot(index=\"Category_1\", columns=\"Category_2\", values=\"Weight\").fillna(0).astype(int)\n",
    "\n",
    "    final_matrix.to_csv(\"network_topic_matrix.csv\")\n",
    "    print(\"Saved Topic Map to 'network_topic_matrix.csv'\")\n",
    "    print(final_matrix)\n",
    "else:\n",
    "    print(\"No edges to map.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91835832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f9e308e850450aa94b80e0c20b62a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=122, bar_style='success', description='Progress:', layout=Layo‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --- 1. CONFIGURATION & DATA LOADING ---\n",
    "filename = \"entities_to_edit.csv\"\n",
    "\n",
    "# --- TAXONOMY (General English) ---\n",
    "TAXONOMY = {\n",
    "    \"Academia\": {\n",
    "        \"Higher Education Institutions (HEIs)\": {\n",
    "            \"desc\": \"Universities, Colleges, Schools (Teaching & Research).\",\n",
    "            \"keywords\": [\n",
    "                \"University\", \"College\", \"School\", \"Academy\", \"Faculty\", \"Department\", \n",
    "                \"Chair\", \"Campus\", \"Institute of Technology\", \"Polytechnic\", \n",
    "                \"Business School\", \"Medical School\", \"Law School\"\n",
    "            ]\n",
    "        },\n",
    "        \"Public Research Orgs (PROs)\": {\n",
    "            \"desc\": \"Research Institutes (Knowledge Output, no teaching).\",\n",
    "            \"keywords\": [\n",
    "                \"Institute\", \"Center\", \"Centre\", \"Laboratory\", \"Lab\", \"Observatory\", \n",
    "                \"National Lab\", \"Research Council\", \"Think Tank\", \"Agency (Research)\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"Industry\": {\n",
    "        \"Private Firms (Corporates)\": {\n",
    "            \"desc\": \"Established Companies, SMEs, MNEs.\",\n",
    "            \"keywords\": [\n",
    "                \"Inc\", \"Corp\", \"Corporation\", \"Ltd\", \"LLC\", \"PLC\", \"Co\", \"Company\", \n",
    "                \"Group\", \"Holdings\", \"Manufacturer\", \"Supplier\", \"Vendor\", \n",
    "                \"Conglomerate\", \"Multinational\", \"Enterprise\", \"Firm\"\n",
    "            ]\n",
    "        },\n",
    "        \"Start-ups\": {\n",
    "            \"desc\": \"Young Growth Companies, Spin-offs.\",\n",
    "            \"keywords\": [\n",
    "                \"Start-up\", \"Startup\", \"Spin-off\", \"Spinoff\", \"Scale-up\", \"Unicorn\", \n",
    "                \"Venture\", \"NewCo\", \"DeepTech\", \"Founder\", \"Stealth Mode\"\n",
    "            ]\n",
    "        },\n",
    "        \"Consulting\": {\n",
    "            \"desc\": \"Services, Advisory, Legal, HR.\",\n",
    "            \"keywords\": [\n",
    "                \"Consulting\", \"Consultancy\", \"Advisors\", \"Partners\", \"Legal\", \"Law Firm\", \n",
    "                \"LLP\", \"Attorney\", \"IP Law\", \"Patent\", \"Audit\", \"Tax\", \"Recruitment\", \n",
    "                \"Headhunter\", \"Strategy\", \"Management\", \"Services\"\n",
    "            ]\n",
    "        },\n",
    "        \"Venture Capital / Investors\": {\n",
    "            \"desc\": \"Financial Actors, VCs, Business Angels.\",\n",
    "            \"keywords\": [\n",
    "                \"Capital\", \"Invest\", \"Investment\", \"Fund\", \"Venture\", \"VC\", \"Equity\", \n",
    "                \"Private Equity\", \"PE\", \"Angel\", \"Seed\", \"Asset Management\", \"Bank\", \n",
    "                \"Financial Group\", \"Holding\", \"Wealth Management\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"Government\": {\n",
    "        \"Policy Makers\": {\n",
    "            \"desc\": \"Ministries, Councils, Parliaments (Regulation).\",\n",
    "            \"keywords\": [\n",
    "                \"Ministry\", \"Department\", \"Dept\", \"Council\", \"Government\", \"Federal\", \n",
    "                \"State\", \"Municipality\", \"City\", \"County\", \"District\", \"Parliament\", \n",
    "                \"Senate\", \"Commission\", \"Mayor\", \"Governor\", \"Regulator\", \"Authority\", \n",
    "                \"Administration\", \"Bureau\"\n",
    "            ]\n",
    "        },\n",
    "        \"Funding Agencies\": {\n",
    "            \"desc\": \"Funding Bodies, Project Management Agencies.\",\n",
    "            \"keywords\": [\n",
    "                \"Foundation\", \"Agency\", \"Grant\", \"Funding\", \"Fund\", \"Endowment\", \n",
    "                \"Trust\", \"Award\", \"Scholarship\", \"Fellowship\", \"Program\", \"Initiative\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"Civil Society\": {\n",
    "        \"Media\": {\n",
    "            \"desc\": \"Press, News, Journals.\",\n",
    "            \"keywords\": [\n",
    "                \"News\", \"Journal\", \"Press\", \"Times\", \"Post\", \"Daily\", \"Review\", \n",
    "                \"Magazine\", \"Publisher\", \"Broadcaster\", \"TV\", \"Radio\", \"Podcast\", \n",
    "                \"Blog\", \"Media\", \"Outlet\", \"Chronicle\", \"Gazette\"\n",
    "            ]\n",
    "        },\n",
    "        \"Cultural Institutions\": {\n",
    "            \"desc\": \"Museums, Libraries, Galleries.\",\n",
    "            \"keywords\": [\n",
    "                \"Museum\", \"Library\", \"Gallery\", \"Theater\", \"Opera\", \"Orchestra\", \n",
    "                \"Archive\", \"Collection\", \"Exhibition\", \"Zoo\", \"Botanical Garden\", \n",
    "                \"Science Center\", \"Planetarium\", \"Hall\"\n",
    "            ]\n",
    "        },\n",
    "        \"NGOs / NPOs\": {\n",
    "            \"desc\": \"Non-Profit, Social Goals, Charities.\",\n",
    "            \"keywords\": [\n",
    "                \"Charity\", \"Non-Profit\", \"NPO\", \"NGO\", \"Organization\", \"Society\", \n",
    "                \"Club\", \"Union\", \"Alliance\", \"Federation\", \"Initiative\", \"Philanthropy\", \n",
    "                \"Foundation (Private)\", \"Mission\", \"Relief\"\n",
    "            ]\n",
    "        },\n",
    "        \"Intermediaries\": {\n",
    "            \"desc\": \"Clusters, Hubs, TTOs, Chambers.\",\n",
    "            \"keywords\": [\n",
    "                \"Cluster\", \"Network\", \"Hub\", \"Incubator\", \"Accelerator\", \"TTO\", \n",
    "                \"Technology Transfer\", \"Chamber of Commerce\", \"Trade Union\", \n",
    "                \"Association\", \"Consortium\", \"Standardization\", \"Body\", \"Council (Trade)\"\n",
    "            ]\n",
    "        },\n",
    "        \"Citizens / Users\": {\n",
    "            \"desc\": \"Citizens, Patients, User Groups.\",\n",
    "            \"keywords\": [\n",
    "                \"Community\", \"Group\", \"Public\", \"Citizen\", \"Patient\", \"User\", \n",
    "                \"Resident\", \"Population\", \"Crowd\", \"Forum\", \"Volunteer\", \"Advocacy\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(filename).fillna(\"\")\n",
    "    required_cols = [\"qh_category\", \"qh_sub_category\", \"qh_exact_category\", \"modified_entity_name\", \"finalized_entity_name\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{filename}' not found.\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# --- 2. WIDGET SETUP ---\n",
    "\n",
    "if not df.empty:\n",
    "    unfinished_indices = df[df['qh_category'] == \"\"].index.tolist()\n",
    "    current_idx = unfinished_indices[0] if unfinished_indices else 0\n",
    "    NEW_OPT = \"+++ Create New +++\"\n",
    "\n",
    "    # Progress Bar\n",
    "    total_items = len(df)\n",
    "    progress = widgets.IntProgress(\n",
    "        value=len(df) - len(unfinished_indices),\n",
    "        min=0,\n",
    "        max=total_items,\n",
    "        description='Progress:',\n",
    "        bar_style='success',\n",
    "        layout=widgets.Layout(width='99%')\n",
    "    )\n",
    "    progress_label = widgets.Label(value=f\"{progress.value} / {total_items} tagged\")\n",
    "\n",
    "    # --- INPUT WIDGETS ---\n",
    "\n",
    "    # 0. Entity Name Editor\n",
    "    w_name_edit = widgets.Text(\n",
    "        description='<b>Edit Name:</b>',\n",
    "        placeholder='Correct the entity name here...',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "\n",
    "    # 1. Main Category\n",
    "    w_helix = widgets.Dropdown(\n",
    "        options=[''] + list(TAXONOMY.keys()) + [NEW_OPT],\n",
    "        description='1. Helix:',\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    w_helix_new = widgets.Text(\n",
    "        placeholder='Type new Helix category...',\n",
    "        layout=widgets.Layout(width='400px', display='none') \n",
    "    )\n",
    "\n",
    "    # 2. Sub Category\n",
    "    w_sub = widgets.Dropdown(\n",
    "        options=[],\n",
    "        description='2. Type:',\n",
    "        layout=widgets.Layout(width='400px'),\n",
    "        disabled=True\n",
    "    )\n",
    "    w_sub_new = widgets.Text(\n",
    "        placeholder='Type new Sub-Category...',\n",
    "        layout=widgets.Layout(width='400px', display='none')\n",
    "    )\n",
    "\n",
    "    # 3. Exact Category (MULTI SELECT)\n",
    "    w_exact_multi = widgets.SelectMultiple(\n",
    "        options=[],\n",
    "        description='3. Exact:',\n",
    "        rows=8, # Height of the box\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    \n",
    "    # Helper text for multi-select\n",
    "    w_multi_help = widgets.HTML(\n",
    "        value=\"<div style='font-size:0.8em; color:#666; margin-left:100px;'><i>Hold <b>Ctrl</b> (Win) or <b>Cmd</b> (Mac) to select multiple.</i></div>\"\n",
    "    )\n",
    "\n",
    "    w_exact_new = widgets.Text(\n",
    "        placeholder='Type NEW keyword here...',\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "    # Button to add the typed keyword to the list immediately\n",
    "    btn_add_exact = widgets.Button(\n",
    "        description='Add to List',\n",
    "        icon='plus',\n",
    "        layout=widgets.Layout(width='100px')\n",
    "    )\n",
    "\n",
    "    # Info & Display\n",
    "    w_info = widgets.HTML(value=\"<div style='color:#666; font-style:italic; margin-left:100px;'>Select a category...</div>\")\n",
    "    w_entity_display = widgets.HTML()\n",
    "    output_log = widgets.Output()\n",
    "\n",
    "    # Buttons\n",
    "    btn_save = widgets.Button(description='Save & Next ‚û°Ô∏è', button_style='primary')\n",
    "    btn_prev = widgets.Button(description='‚¨ÖÔ∏è Previous')\n",
    "\n",
    "    # --- 3. LOGIC ---\n",
    "\n",
    "    def get_split_history():\n",
    "        \"\"\"Reads all exact categories, splits by ';', and returns unique items for the dropdown.\"\"\"\n",
    "        all_vals = df['qh_exact_category'].dropna().unique()\n",
    "        unique_items = set()\n",
    "        for val in all_vals:\n",
    "            if str(val) == \"nan\" or str(val).strip() == \"\": continue\n",
    "            parts = [p.strip() for p in str(val).split(';')]\n",
    "            for p in parts:\n",
    "                if p: unique_items.add(p)\n",
    "        return sorted(list(unique_items))\n",
    "\n",
    "    def update_display():\n",
    "        \"\"\"Refreshes UI for current row.\"\"\"\n",
    "        if current_idx >= len(df):\n",
    "            w_entity_display.value = \"<div style='background:#d4edda; color:#155724; padding:15px;'><h3>üéâ All Done!</h3></div>\"\n",
    "            return\n",
    "\n",
    "        row = df.loc[current_idx]\n",
    "        \n",
    "        # Display Context\n",
    "        w_entity_display.value = f\"\"\"\n",
    "        <div style=\"background-color: #f8f9fa; border-left: 5px solid #0d6efd; padding: 15px; margin-bottom: 10px;\">\n",
    "            <div style=\"margin-bottom: 5px; font-size: 0.9em; color: #495057;\">\n",
    "                <b>Original Entity:</b> <span style=\"font-family: monospace; font-size: 1.1em;\">{row['entity_name']}</span>\n",
    "            </div>\n",
    "            <div style=\"font-size: 0.85em; color: #666;\">\n",
    "                Doc: {row.get('Document_Name', 'N/A')} | Year: {row.get('Year', 'N/A')}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Name Edit\n",
    "        existing_final = str(row['finalized_entity_name'])\n",
    "        if existing_final and existing_final.strip() != \"\" and existing_final != \"nan\":\n",
    "            w_name_edit.value = existing_final\n",
    "        else:\n",
    "            w_name_edit.value = str(row['entity_name'])\n",
    "\n",
    "        # Load Categories\n",
    "        current_cat = row['qh_category']\n",
    "        current_sub = row['qh_sub_category']\n",
    "        current_exact = str(row['qh_exact_category'])\n",
    "\n",
    "        # 1. Set Helix\n",
    "        if current_cat in w_helix.options:\n",
    "            w_helix.value = current_cat\n",
    "        elif current_cat:\n",
    "            w_helix.options = list(w_helix.options)[:-1] + [current_cat, NEW_OPT]\n",
    "            w_helix.value = current_cat\n",
    "        else:\n",
    "            w_helix.value = ''\n",
    "\n",
    "        # 2. Set Sub (Trigger updates)\n",
    "        update_sub_options(w_helix.value)\n",
    "        if current_sub in w_sub.options:\n",
    "            w_sub.value = current_sub\n",
    "        elif current_sub:\n",
    "            w_sub.options = list(w_sub.options)[:-1] + [current_sub, NEW_OPT]\n",
    "            w_sub.value = current_sub\n",
    "            \n",
    "        # 3. Set Exact (Trigger updates based on Sub)\n",
    "        update_exact_options(w_helix.value, w_sub.value)\n",
    "        \n",
    "        # Handle Pre-selection of Multiple Items\n",
    "        if current_exact and current_exact != \"nan\" and current_exact.strip():\n",
    "            # Split by semicolon\n",
    "            selected_items = [x.strip() for x in current_exact.split(';')]\n",
    "            # Ensure they exist in options\n",
    "            current_options = list(w_exact_multi.options)\n",
    "            for item in selected_items:\n",
    "                if item not in current_options and item != \"\":\n",
    "                    current_options.append(item)\n",
    "            \n",
    "            w_exact_multi.options = sorted(current_options)\n",
    "            \n",
    "            # Set Value (must be a tuple of matching strings)\n",
    "            valid_selection = [x for x in selected_items if x in w_exact_multi.options]\n",
    "            w_exact_multi.value = tuple(valid_selection)\n",
    "        else:\n",
    "            w_exact_multi.value = ()\n",
    "\n",
    "        # Reset New Fields\n",
    "        w_helix_new.layout.display = 'none'\n",
    "        w_sub_new.layout.display = 'none'\n",
    "        w_exact_new.value = '' # Clear new keyword box\n",
    "\n",
    "        # Progress\n",
    "        done_count = len(df[df['qh_category'] != \"\"])\n",
    "        progress.value = done_count\n",
    "        progress_label.value = f\"{done_count} / {total_items} tagged\"\n",
    "\n",
    "    def update_sub_options(main_cat):\n",
    "        if main_cat in TAXONOMY:\n",
    "            opts = sorted(list(TAXONOMY[main_cat].keys()))\n",
    "            w_sub.options = [''] + opts + [NEW_OPT]\n",
    "            w_sub.disabled = False\n",
    "        elif main_cat and main_cat != NEW_OPT:\n",
    "            w_sub.options = [''] + [NEW_OPT]\n",
    "            w_sub.disabled = False\n",
    "        else:\n",
    "            w_sub.options = []\n",
    "            w_sub.disabled = True\n",
    "\n",
    "    def update_exact_options(main, sub):\n",
    "        \"\"\"Populates SelectMultiple with Keywords + Single Item History\"\"\"\n",
    "        options = []\n",
    "        \n",
    "        # 1. Add Taxonomy Keywords\n",
    "        if main in TAXONOMY and sub in TAXONOMY[main]:\n",
    "            keywords = sorted(TAXONOMY[main][sub].get('keywords', []))\n",
    "            options += keywords\n",
    "        \n",
    "        # 2. Add Global History (Split individual items)\n",
    "        history = get_split_history()\n",
    "        # Merge and Unique\n",
    "        combined = sorted(list(set(options + history)))\n",
    "        \n",
    "        w_exact_multi.options = combined\n",
    "\n",
    "    # --- EVENT HANDLERS ---\n",
    "\n",
    "    def on_helix_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            val = change['new']\n",
    "            if val == NEW_OPT:\n",
    "                w_helix_new.layout.display = 'block'\n",
    "                w_sub.options = [''] + [NEW_OPT]\n",
    "                w_sub.disabled = False\n",
    "                w_info.value = \"\"\n",
    "            else:\n",
    "                w_helix_new.layout.display = 'none'\n",
    "                update_sub_options(val)\n",
    "                update_exact_options(val, '')\n",
    "                w_info.value = \"\"\n",
    "\n",
    "    def on_sub_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            val = change['new']\n",
    "            main = w_helix.value\n",
    "            \n",
    "            if val == NEW_OPT:\n",
    "                w_sub_new.layout.display = 'block'\n",
    "                w_info.value = \"\"\n",
    "            else:\n",
    "                w_sub_new.layout.display = 'none'\n",
    "                update_exact_options(main, val)\n",
    "                \n",
    "                if main in TAXONOMY and val in TAXONOMY[main]:\n",
    "                    desc = TAXONOMY[main][val]['desc']\n",
    "                    w_info.value = f\"<div style='color:#0d6efd; margin-left:100px;'>‚ÑπÔ∏è {desc}</div>\"\n",
    "\n",
    "    def add_new_keyword(b):\n",
    "        \"\"\"Adds text from input box to the multiple selection list and selects it.\"\"\"\n",
    "        new_val = w_exact_new.value.strip()\n",
    "        if new_val:\n",
    "            # Add to options\n",
    "            current_opts = list(w_exact_multi.options)\n",
    "            if new_val not in current_opts:\n",
    "                current_opts.append(new_val)\n",
    "                w_exact_multi.options = sorted(current_opts)\n",
    "            \n",
    "            # Add to selection\n",
    "            current_sel = list(w_exact_multi.value)\n",
    "            if new_val not in current_sel:\n",
    "                current_sel.append(new_val)\n",
    "                w_exact_multi.value = tuple(current_sel)\n",
    "            \n",
    "            w_exact_new.value = \"\" # Clear input\n",
    "\n",
    "    def save_and_next(b):\n",
    "        global current_idx\n",
    "        \n",
    "        # 1. Name Logic\n",
    "        original_name = str(df.at[current_idx, 'entity_name']).strip()\n",
    "        new_name_input = str(w_name_edit.value).strip()\n",
    "        \n",
    "        if new_name_input != original_name:\n",
    "            df.at[current_idx, 'modified_entity_name'] = True\n",
    "            df.at[current_idx, 'finalized_entity_name'] = new_name_input\n",
    "            name_log = f\"Edited name\"\n",
    "        else:\n",
    "            df.at[current_idx, 'modified_entity_name'] = False\n",
    "            df.at[current_idx, 'finalized_entity_name'] = original_name\n",
    "            name_log = \"Name original\"\n",
    "\n",
    "        # 2. Category Logic\n",
    "        val_cat = w_helix_new.value if w_helix.value == NEW_OPT else w_helix.value\n",
    "        val_sub = w_sub_new.value if w_sub.value == NEW_OPT else w_sub.value\n",
    "        \n",
    "        # Process Exact: Join tuple values with semicolon\n",
    "        selected_exacts = w_exact_multi.value\n",
    "        val_exact = \"; \".join(selected_exacts)\n",
    "        \n",
    "        # Learn Main\n",
    "        if w_helix.value == NEW_OPT and val_cat:\n",
    "            if val_cat not in TAXONOMY:\n",
    "                TAXONOMY[val_cat] = {}\n",
    "                opts = list(w_helix.options)\n",
    "                opts.insert(-1, val_cat)\n",
    "                w_helix.options = opts\n",
    "        \n",
    "        # Learn Sub\n",
    "        if w_sub.value == NEW_OPT and val_sub:\n",
    "            if val_cat not in TAXONOMY: TAXONOMY[val_cat] = {}\n",
    "            if val_sub not in TAXONOMY[val_cat]:\n",
    "                TAXONOMY[val_cat][val_sub] = {'desc': 'User Added', 'keywords': []}\n",
    "            opts = list(w_sub.options)\n",
    "            opts.insert(-1, val_sub)\n",
    "            w_sub.options = opts\n",
    "\n",
    "        # Exact History Learning is handled automatically next time get_split_history is called on the DF\n",
    "\n",
    "        # Save to DF\n",
    "        df.at[current_idx, 'qh_category'] = val_cat\n",
    "        df.at[current_idx, 'qh_sub_category'] = val_sub\n",
    "        df.at[current_idx, 'qh_exact_category'] = val_exact\n",
    "        \n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "        with output_log:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"‚úÖ Saved. ({name_log})\")\n",
    "\n",
    "        # Next\n",
    "        if current_idx < len(df) - 1:\n",
    "            current_idx += 1\n",
    "            update_display()\n",
    "        else:\n",
    "            with output_log:\n",
    "                print(\"End of list reached.\")\n",
    "\n",
    "    def go_prev(b):\n",
    "        global current_idx\n",
    "        if current_idx > 0:\n",
    "            current_idx -= 1\n",
    "            update_display()\n",
    "\n",
    "    # --- 4. LAYOUT ---\n",
    "    w_helix.observe(on_helix_change)\n",
    "    w_sub.observe(on_sub_change)\n",
    "    btn_add_exact.on_click(add_new_keyword)\n",
    "    \n",
    "    btn_save.on_click(save_and_next)\n",
    "    btn_prev.on_click(go_prev)\n",
    "\n",
    "    update_display()\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([progress, progress_label]),\n",
    "        w_entity_display,\n",
    "        \n",
    "        w_name_edit,\n",
    "        widgets.HTML(\"<div style='height:10px;'></div>\"),\n",
    "\n",
    "        w_helix, w_helix_new,\n",
    "        w_sub, w_sub_new,\n",
    "        w_info,\n",
    "        \n",
    "        widgets.HTML(\"<hr style='margin: 5px 0; border:0; border-top:1px solid #eee;'>\"),\n",
    "        \n",
    "        # Exact Multi Select Section\n",
    "        widgets.VBox([\n",
    "            w_exact_multi,\n",
    "            w_multi_help,\n",
    "            widgets.HBox([w_exact_new, btn_add_exact])\n",
    "        ]),\n",
    "        \n",
    "        widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
    "        widgets.HBox([btn_prev, btn_save]),\n",
    "        output_log\n",
    "    ])\n",
    "    \n",
    "    display(ui)\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12349687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run again deduplication and save\n",
    "#TODO Run again deduplication and save: since modified_entities might have created duplicates\n",
    "# Eigentlich ja noch Entities und deren Abk√ºrzungen zusammenfassen sonst gibt es ja bei Entities mit Abk√ºrzungen doppelte Eintr√§ge\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
